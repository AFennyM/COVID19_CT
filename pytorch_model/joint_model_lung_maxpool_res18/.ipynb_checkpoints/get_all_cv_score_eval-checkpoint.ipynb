{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from skimage import transform as sktr\n",
    "from skimage import morphology\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "\n",
    "import albumentations as Alb\n",
    "import torch\n",
    "import torchvision.models as tmodels\n",
    "from cv2 import BORDER_CONSTANT, BORDER_REPLICATE, BORDER_REFLECT\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import torchvision.transforms as ttransforms\n",
    "import torch\n",
    "import torchvision.models as tmodels\n",
    "import torch.utils.data as tdata\n",
    "from skimage.io import imread\n",
    "import random\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from model import construct_model\n",
    "from helpers import *\n",
    "from model_main_ops import get_cv\n",
    "from model_main_ops.datareader import DataReader, train_aug_ops, constant_ops\n",
    "from model_main_ops.performance_metric import ScoreRecorder, compute_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('/data/COVID19_clinical_data/clinical_info_joint.csv')\n",
    "\n",
    "res = []\n",
    "model = construct_model()\n",
    "model.cuda()\n",
    "\n",
    "for model_to_use in ['model_best.pth', 'model_last.pth']:\n",
    "    for cv_fold in range(5):\n",
    "\n",
    "        _folder_to_save = 'model_cv%d' % cv_fold\n",
    "        fn_img_prob = '_'.join([model_to_use.split('.')[0], 'prob_img_cv%d.csv' % cv_fold])\n",
    "        fn_ave_prob = '_'.join([model_to_use.split('.')[0], 'prob_ave_cv%d.csv' % cv_fold])\n",
    "\n",
    "        val_info, _, pid2features = get_cv.get_eval_split()\n",
    "        val_datareader = DataReader(val_info, pid2features, transform=constant_ops)\n",
    "        val_generator = tdata.DataLoader(val_datareader, batch_size=16, shuffle=False, pin_memory = True)\n",
    "\n",
    "\n",
    "        model.load_state_dict(torch.load(os.path.join(_folder_to_save, model_to_use) ))\n",
    "        \n",
    "        prob = np.squeeze(model.get_logits(val_generator, is_prob=True))\n",
    "        if cv_fold == 0:\n",
    "            pred_prob = prob\n",
    "        else:\n",
    "            pred_prob += prob\n",
    "        \n",
    "        df_test = pd.DataFrame([[f[0], f[2]] + [v] for f, v in zip(val_info, prob)])\n",
    "        df_mean = df_test.groupby([0, 1]).mean()\n",
    "        \n",
    "        fn_ave_prob = '_'.join([model_to_use.split('.')[0], 'prob_ave_val.csv'])  \n",
    "        df_mean.to_csv(os.path.join(_folder_to_save, fn_ave_prob)) \n",
    "        \n",
    "    pred_prob /= 5.\n",
    "    \n",
    "    df_test = pd.DataFrame([[f[0], f[2]] + [v] for f, v in zip(val_info, pred_prob)])\n",
    "    df_mean = df_test.groupby([0, 1]).mean()\n",
    "\n",
    "    fn_ave_prob = '_'.join([model_to_use.split('.')[0], 'prob_ave_ensemble_val.csv'])  \n",
    "    df_mean.to_csv(fn_ave_prob)\n",
    "\n",
    "    \n",
    "    for mc in ['all']:\n",
    "        if mc == 'all':\n",
    "            tmp0 = set(df_sample.pid)\n",
    "        else:\n",
    "            tmp0 = set(df_sample[df_sample.center == mc].pid)\n",
    "            \n",
    "        tmp = df_mean[[i[0] in tmp0 for i in df_mean.index]]\n",
    "\n",
    "        per_patient_prob = tmp[2].values\n",
    "        per_patient_label = np.array([v[1] for v in tmp.index])\n",
    "\n",
    "        scores = compute_metric(per_patient_prob, per_patient_label, threshold = 0.3)\n",
    "        tmp = [model_to_use, mc] + list(scores)\n",
    "        res.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res, columns = ['model', 'center', 'accuracy', 'sensitivity', 'specificity', 'ppv', 'npv', 'auc_roc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>center</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>ppv</th>\n",
       "      <th>npv</th>\n",
       "      <th>auc_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_best.pth</td>\n",
       "      <td>all</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.957285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_last.pth</td>\n",
       "      <td>all</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.955861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model center  accuracy  sensitivity  specificity       ppv  \\\n",
       "0  model_best.pth    all  0.869565     0.953488     0.795918  0.803922   \n",
       "1  model_last.pth    all  0.891304     0.953488     0.836735  0.836735   \n",
       "\n",
       "        npv   auc_roc  \n",
       "0  0.951220  0.957285  \n",
       "1  0.953488  0.955861  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
